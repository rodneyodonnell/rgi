{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1440ce-9dee-447c-93a5-65b8c7e889e3",
   "metadata": {},
   "source": [
    "# Trainer NNX scratchpad\n",
    "\n",
    "Generate training data\n",
    "```\n",
    "python rgi/main.py --game connect4 --player1 random --player2 random --num_games 100 --save_trajectories\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "from flax import nnx  # The Flax NNX API.\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "print(jax.devices())\n",
    "assert jax.devices()[0].platform == 'gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.core import trajectory\n",
    "from rgi.players.zerozero.zerozero_trainer import ZeroZeroTrainer\n",
    "from rgi.players.zerozero.zerozero_model import ZeroZeroModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36570865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.core import game_registry\n",
    "GAMES: dict[str, game_registry.RegisteredGame[Any, Any, Any]] = game_registry.GAME_REGISTRY\n",
    "PLAYERS: dict[str, Any] = game_registry.PLAYER_REGISTRY\n",
    "\n",
    "game_name = \"connect4\"\n",
    "registered_game = GAMES[game_name]\n",
    "serializer = registered_game.serializer_fn()\n",
    "state_embedder = registered_game.state_embedder_fn()\n",
    "action_embedder = registered_game.action_embedder_fn()\n",
    "game = registered_game.game_fn()\n",
    "\n",
    "trajectories_glob = os.path.join(\"..\", \"data\", \"trajectories\", game_name, \"*.trajectory.npy\")\n",
    "trajectories = trajectory.load_trajectories(trajectories_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44221c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Connect4StateEmbedder(nnx.Module):\n",
    "    embedding_dim: int = 64\n",
    "    hidden_dim: int = 256\n",
    "\n",
    "    def _state_to_array(self, encoded_state_batch: jax.Array) -> jax.Array:\n",
    "        board_array = encoded_state_batch[:, :-1].reshape([-1, 6, 7])\n",
    "        return board_array\n",
    "\n",
    "    def __init__(self, *, rngs: nnx.Rngs):\n",
    "        self.conv1 = nnx.Conv(1, 32, kernel_size=(3, 3), rngs=rngs)\n",
    "        self.conv2 = nnx.Conv(32, 64, kernel_size=(3, 3), rngs=rngs)\n",
    "        self.linear1 = nnx.Linear(6*7*64, self.hidden_dim, rngs=rngs)\n",
    "        self.linear2 = nnx.Linear(self.hidden_dim, self.embedding_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, encoded_state_batch: jax.Array):\n",
    "        x = self._state_to_array(encoded_state_batch)\n",
    "        x = x[..., None]  # Add channel dimension\n",
    "        x = nnx.relu(self.conv1(x))\n",
    "        x = nnx.relu(self.conv2(x))\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten while preserving batch dimension\n",
    "        x = nnx.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        # normalize x, Add epsilon to avoid division by zero\n",
    "        epsilon = 1e-8  \n",
    "        x += epsilon\n",
    "        x = x / jnp.linalg.norm(x, axis=1, keepdims=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "state_0 = game.initial_state()\n",
    "state_1 = game.next_state(state_0, 2)\n",
    "\n",
    "encoded_states_batch = jnp.array([\n",
    "    serializer.state_to_jax_array(game, state_0),\n",
    "    serializer.state_to_jax_array(game, state_1),\n",
    "])\n",
    "# encoded_state_batch = jnp.expand_dims(encoded_states, axis=0)\n",
    "print(f'encoded_states_batch.shape: {encoded_states_batch.shape}')\n",
    "\n",
    "state_embedder = Connect4StateEmbedder(rngs=nnx.Rngs(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b11059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect4ActionEmbedder(nnx.Module):\n",
    "    embedding_dim: int = 64\n",
    "    num_actions: int = 7\n",
    "\n",
    "    def __init__(self, *, rngs: nnx.Rngs):\n",
    "        self.embedding = nnx.Embed(num_embeddings=self.num_actions, features=self.embedding_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, action: jax.Array) -> jax.Array:\n",
    "        # Ensure action is 0-indexed\n",
    "        action = action - 1\n",
    "        return self.embedding(action)\n",
    "    \n",
    "    def all_action_embeddings(self):\n",
    "        return self(jnp.arange(1,self.num_actions+1))\n",
    "\n",
    "action_embedder = Connect4ActionEmbedder(rngs=nnx.Rngs(0))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97163fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'trajectories_glob: {trajectories_glob}')\n",
    "print(f'num_trajectories: {len(trajectories)}')\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter((t.actions[0].item(), t.final_rewards[0].item()) for t in trajectories)\n",
    "\n",
    "for action in range(1,7+1):\n",
    "    win_count, loss_count = c[(action, 1.0)], c[(action, -1.0)]\n",
    "    print(f'action: {action}, win: {win_count:3d}, loss: {loss_count:3d}, win_pct: {win_count / (win_count + loss_count) * 100:.2f}%')\n",
    "    \n",
    "# num_trajectories: 100\n",
    "# action: 1, win:  14, loss:   9, win_pct: 60.87%\n",
    "# action: 2, win:   6, loss:   6, win_pct: 50.00%\n",
    "# action: 3, win:   8, loss:   4, win_pct: 66.67%\n",
    "# action: 4, win:  11, loss:   3, win_pct: 78.57%\n",
    "# action: 5, win:  11, loss:   5, win_pct: 68.75%\n",
    "# action: 6, win:   8, loss:   5, win_pct: 61.54%\n",
    "# action: 7, win:   5, loss:   5, win_pct: 50.00%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.core.trajectory import EncodedTrajectory\n",
    "\n",
    "# define trajectory NamedTuple\n",
    "from typing import NamedTuple\n",
    "class TrajectoryStep(NamedTuple):\n",
    "    move_index: int\n",
    "    state: jax.Array\n",
    "    action: jax.Array\n",
    "    next_state: jax.Array\n",
    "    reward: jax.Array\n",
    "\n",
    "\n",
    "def unroll_trajectory(encoded_trajectories: list[EncodedTrajectory]):\n",
    "    for t in encoded_trajectories:\n",
    "        for i in range(t.length - 1):\n",
    "            yield TrajectoryStep(i, t.states[i], t.actions[i], t.states[i + 1], t.state_rewards[i])\n",
    "\n",
    "t_steps_list = list(unroll_trajectory(trajectories))\n",
    "print(f'num_trajectory_steps: {len(t_steps_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_embedder\n",
    "# state_batch = jnp.array([t_steps_list[0].state, t_steps_list[1].state])\n",
    "state_batch = jnp.array([t.state for t in t_steps_list])\n",
    "state_embedder(state_batch[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_batch = jnp.array([t_steps_list[0].action, t_steps_list[1].action])\n",
    "action_batch = jnp.array([t.action for t in t_steps_list])\n",
    "action_embedder(action_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = nnx.Optimizer(state_embedder, optax.adamw(learning_rate, momentum))\n",
    "metrics = nnx.MultiMetric(\n",
    "  accuracy=nnx.metrics.Accuracy(),\n",
    "  loss=nnx.metrics.Average('loss'),\n",
    ")\n",
    "\n",
    "# nnx.display(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238dd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(action_batch), len(state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model: Connect4StateEmbedder, batch):\n",
    "  logits = model(batch['state'])\n",
    "  loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "    logits=logits, labels=batch['action']\n",
    "  ).mean()\n",
    "  return loss, logits\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: Connect4StateEmbedder, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "  (loss, logits), grads = grad_fn(model, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['action'])  # In-place updates.\n",
    "  optimizer.update(grads)  # In-place updates.\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model: Connect4StateEmbedder, metrics: nnx.MultiMetric, batch):\n",
    "  loss, logits = loss_fn(model, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['action'])  # In-place updates.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {'state': state_batch, 'action': action_batch}\n",
    "loss, logits = loss_fn(state_embedder, batch)\n",
    "\n",
    "loss, logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7da81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ec8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_history = {\n",
    "#   'train_loss': [],\n",
    "#   'train_accuracy': [],\n",
    "#   'test_loss': [],\n",
    "#   'test_accuracy': [],\n",
    "# }\n",
    "\n",
    "# for _ in range(1000):\n",
    "#     train_step(state_embedder, optimizer, metrics, batch)\n",
    "\n",
    "# for metric, value in metrics.compute().items():  # Compute the metrics.\n",
    "#     metrics_history[f'train_{metric}'].append(value)  # Record the metrics.\n",
    "# metrics.reset()  # Reset the metrics for the test set.\n",
    "\n",
    "# eval_step(state_embedder, metrics, batch)\n",
    "\n",
    "# # Log the test metrics.\n",
    "# for metric, value in metrics.compute().items():\n",
    "#     metrics_history[f'test_{metric}'].append(value)\n",
    "# metrics.reset()  # Reset the metrics for the next training epoch.\n",
    "\n",
    "# print(\n",
    "#     f\"[train] step: {1}, \"\n",
    "#     f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
    "#     f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\"\n",
    "# )\n",
    "# print(\n",
    "#     f\"[test] step: {1}, \"\n",
    "#     f\"loss: {metrics_history['test_loss'][-1]}, \"\n",
    "#     f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\"\n",
    "# )\n",
    "\n",
    "# # [train] step: 1, loss: 3.2814717292785645, accuracy: 87.06680297851562\n",
    "# # [test] step: 1, loss: 3.252131223678589, accuracy: 90.15047454833984\n",
    "\n",
    "# # [train] step: 1, loss: 3.252079963684082, accuracy: 90.15047454833984\n",
    "# # [test] step: 1, loss: 3.2519733905792236, accuracy: 90.15047454833984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_embedder(state_batch[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d73985",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_2 = {k:v[:2] for k,v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8d5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_2(state_embedder: Connect4StateEmbedder, action_embedder: Connect4ActionEmbedder, batch):\n",
    "    state_embeddings = state_embedder(batch['state'])\n",
    "    all_action_embeddings = action_embedder.all_action_embeddings()\n",
    "    logits = state_embeddings @ all_action_embeddings.T\n",
    "    # labels = jax.nn.one_hot(batch['action']-1, num_classes=7)\n",
    "    labels = batch['action']-1\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=labels).mean()\n",
    "    return loss, logits\n",
    "\n",
    "batch_1 = {'state': state_batch[:1], 'action': action_batch[:1]}\n",
    "batch_2 = {'state': state_batch[:2], 'action': action_batch[:2]}\n",
    "loss_fn_2(state_embedder, action_embedder, batch_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae318f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(state_embedder: Connect4StateEmbedder, action_embedder: Connect4ActionEmbedder, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  grad_fn = nnx.value_and_grad(loss_fn_2, has_aux=True)\n",
    "  (loss, logits), grads = grad_fn(state_embedder, action_embedder, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['action']-1)  # In-place updates.\n",
    "  optimizer.update(grads)  # In-place updates.\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(state_embedder: Connect4StateEmbedder, action_embedder: Connect4ActionEmbedder, metrics: nnx.MultiMetric, batch):\n",
    "  loss, logits = loss_fn_2(state_embedder, action_embedder, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['action'])  # In-place updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cde5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch['state'].shape\n",
    "# batch_2['state'].shape\n",
    "\n",
    "# jnp.array([batch_2['state'], batch_2['state'], batch_2['state'], batch_2['state']]).shape\n",
    "\n",
    "batch_repeated = {'state': jnp.tile(batch_2['state'], (1000,1)), 'action': jnp.tile(batch_2['action'], (1000,))}\n",
    "# # Duplicate the batch 4 times\n",
    "# b0 = batch_2['state']\n",
    "# # b1 = jnp.array([b0,b0,b0,b0])\n",
    "# b1 = jnp.tile(b0, (4,1))\n",
    "# b0.shape, b1.shape\n",
    "batch_repeated['state'].shape, batch_repeated['action'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "  'train_loss': [],\n",
    "  'train_accuracy': [],\n",
    "  'test_loss': [],\n",
    "  'test_accuracy': [],\n",
    "}\n",
    "\n",
    "train_steps = 1200\n",
    "eval_every = 200\n",
    "batch_size = 32\n",
    "\n",
    "# train_batches = [(i, batch) for i in range(2000)]\n",
    "# test_batches = [(i, batch) for i in range(100)]\n",
    "\n",
    "train_batches = [(i, batch_repeated) for i in range(2000)]\n",
    "test_batches = [(i, batch_repeated) for i in range(100)]\n",
    "\n",
    "\n",
    "# for step, batch in enumerate(train_ds.as_numpy_iterator()):\n",
    "for step, batch in train_batches:\n",
    "  # Run the optimization for one step and make a stateful update to the following:\n",
    "  # - The train state's model parameters\n",
    "  # - The optimizer state\n",
    "  # - The training loss and accuracy batch metrics\n",
    "  with jax.disable_jit():\n",
    "    train_step(state_embedder, action_embedder, optimizer, metrics, batch)\n",
    "  #train_step(state_embedder, action_embedder, optimizer, metrics, batch)\n",
    "\n",
    "  if step > 0 and (step % eval_every == 0 or step == train_steps - 1):  # One training epoch has passed.\n",
    "    # Log the training metrics.\n",
    "    for metric, value in metrics.compute().items():  # Compute the metrics.\n",
    "      metrics_history[f'train_{metric}'].append(value)  # Record the metrics.\n",
    "    metrics.reset()  # Reset the metrics for the test set.\n",
    "\n",
    "    # Compute the metrics on the test set after each training epoch.\n",
    "    for _, test_batch in test_batches:\n",
    "      eval_step(state_embedder, action_embedder, metrics, test_batch)\n",
    "\n",
    "    # Log the test metrics.\n",
    "    for metric, value in metrics.compute().items():\n",
    "      metrics_history[f'test_{metric}'].append(value)\n",
    "    metrics.reset()  # Reset the metrics for the next training epoch.\n",
    "\n",
    "    print(\n",
    "      f\"[train] step: {step}, \"\n",
    "      f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
    "      f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\"\n",
    "    )\n",
    "    # print(\n",
    "    #   f\"[test] step: {step}, \"\n",
    "    #   f\"loss: {metrics_history['test_loss'][-1]}, \"\n",
    "    #   f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\"\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateToActionModel(nnx.Module):\n",
    "    state_embedder: Connect4StateEmbedder\n",
    "    action_embedder: Connect4ActionEmbedder\n",
    "\n",
    "    embedding_dim: int = 64\n",
    "    num_actions: int = 7\n",
    "\n",
    "    def __init__(self, state_embedder: Connect4StateEmbedder, action_embedder: Connect4ActionEmbedder, *, rngs: nnx.Rngs):\n",
    "        self.state_embedder = state_embedder\n",
    "        self.action_embedder = action_embedder\n",
    "\n",
    "    def __call__(self, state: jax.Array) -> jax.Array:\n",
    "        return self.logits(state)\n",
    "\n",
    "    def logits(self, state_batch: jax.Array) -> jax.Array:\n",
    "        state_embeddings = self.state_embedder(state_batch)\n",
    "        all_action_embeddings = self.action_embedder.all_action_embeddings()\n",
    "        logits = state_embeddings @ all_action_embeddings.T\n",
    "        return logits\n",
    "    \n",
    "    def probs(self, state_batch: jax.Array) -> jax.Array:\n",
    "        logits = self.logits(state_batch)\n",
    "        return jax.nn.softmax(logits)\n",
    "\n",
    "\n",
    "state_action_model = StateToActionModel(state_embedder, action_embedder, rngs=nnx.Rngs(0))\n",
    "\n",
    "logits = state_action_model.logits(state_batch[:2])\n",
    "probs = state_action_model.probs(state_batch[:2])\n",
    "\n",
    "print(f'logits: {logits}')\n",
    "print(f'probs: {probs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a23de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
