{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1440ce-9dee-447c-93a5-65b8c7e889e3",
   "metadata": {},
   "source": [
    "# Trainer NNX scratchpad\n",
    "\n",
    "Generate training data\n",
    "```\n",
    "python rgi/main.py --game connect4 --player1 random --player2 random --num_games 100 --save_trajectories\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19b2dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "from flax import nnx  # The Flax NNX API.\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "print(jax.devices())\n",
    "assert jax.devices()[0].platform == 'gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e34972",
   "metadata": {},
   "source": [
    "# Load Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d5ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trajectories: 100\n"
     ]
    }
   ],
   "source": [
    "from rgi.core import trajectory\n",
    "\n",
    "game_name = \"connect4\"\n",
    "trajectories_glob = os.path.join(\"..\", \"data\", \"trajectories\", game_name, \"*.trajectory.npy\")\n",
    "trajectories = trajectory.load_trajectories(trajectories_glob)\n",
    "\n",
    "print(f'num_trajectories: {len(trajectories)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322895c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectories_glob: ../data/trajectories/connect4/*.trajectory.npy\n",
      "num_trajectories: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 19:13:53.759849: W external/xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.6.77. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: 1, win:  14, loss:   9, win_pct: 60.87%\n",
      "action: 2, win:   6, loss:   6, win_pct: 50.00%\n",
      "action: 3, win:   8, loss:   4, win_pct: 66.67%\n",
      "action: 4, win:  11, loss:   3, win_pct: 78.57%\n",
      "action: 5, win:  11, loss:   5, win_pct: 68.75%\n",
      "action: 6, win:   8, loss:   5, win_pct: 61.54%\n",
      "action: 7, win:   5, loss:   5, win_pct: 50.00%\n"
     ]
    }
   ],
   "source": [
    "print(f'trajectories_glob: {trajectories_glob}')\n",
    "print(f'num_trajectories: {len(trajectories)}')\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter((t.actions[0].item(), t.final_rewards[0].item()) for t in trajectories)\n",
    "\n",
    "for action in range(1,7+1):\n",
    "    win_count, loss_count = c[(action, 1.0)], c[(action, -1.0)]\n",
    "    print(f'action: {action}, win: {win_count:3d}, loss: {loss_count:3d}, win_pct: {win_count / (win_count + loss_count) * 100:.2f}%')\n",
    "    \n",
    "# num_trajectories: 100\n",
    "# action: 1, win:  14, loss:   9, win_pct: 60.87%\n",
    "# action: 2, win:   6, loss:   6, win_pct: 50.00%\n",
    "# action: 3, win:   8, loss:   4, win_pct: 66.67%\n",
    "# action: 4, win:  11, loss:   3, win_pct: 78.57%\n",
    "# action: 5, win:  11, loss:   5, win_pct: 68.75%\n",
    "# action: 6, win:   8, loss:   5, win_pct: 61.54%\n",
    "# action: 7, win:   5, loss:   5, win_pct: 50.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5872e996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trajectory_steps: 2193\n"
     ]
    }
   ],
   "source": [
    "from rgi.core.trajectory import EncodedTrajectory\n",
    "\n",
    "# define trajectory NamedTuple\n",
    "from typing import NamedTuple\n",
    "class TrajectoryStep(NamedTuple):\n",
    "    move_index: int\n",
    "    state: jax.Array\n",
    "    action: jax.Array\n",
    "    next_state: jax.Array\n",
    "    reward: jax.Array\n",
    "\n",
    "\n",
    "def unroll_trajectory(encoded_trajectories: list[EncodedTrajectory]):\n",
    "    for t in encoded_trajectories:\n",
    "        for i in range(t.length - 1):\n",
    "            yield TrajectoryStep(i, t.states[i], t.actions[i], t.states[i + 1], t.state_rewards[i])\n",
    "\n",
    "t_steps_list = list(unroll_trajectory(trajectories))\n",
    "print(f'num_trajectory_steps: {len(t_steps_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c8bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_batch = jnp.array([t.state for t in t_steps_list])\n",
    "action_batch = jnp.array([t.action for t in t_steps_list])\n",
    "batch_full = {'state': state_batch, 'action': action_batch}\n",
    "batch_1 = {'state': state_batch[:1], 'action': action_batch[:1]}\n",
    "batch_2 = {'state': state_batch[:2], 'action': action_batch[:2]}\n",
    "\n",
    "# Super easy to get 100% accuracy.\n",
    "batch_repeated = {'state': jnp.tile(batch_2['state'], (1000,1)), 'action': jnp.tile(batch_2['action'], (1000,))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce65ffe",
   "metadata": {},
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36570865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.games import connect4\n",
    "game = connect4.Connect4Game()\n",
    "serializer = connect4.Connect4Serializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44221c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "class Connect4StateEmbedder(nnx.Module):\n",
    "    embedding_dim: int = 64\n",
    "    hidden_dim: int = 256\n",
    "\n",
    "    def _state_to_array(self, encoded_state_batch: jax.Array) -> jax.Array:\n",
    "        board_array = encoded_state_batch[:, :-1].reshape([-1, 6, 7])\n",
    "        return board_array\n",
    "\n",
    "    def __init__(self, *, rngs: nnx.Rngs):\n",
    "        self.conv1 = nnx.Conv(1, 32, kernel_size=(3, 3), rngs=rngs)\n",
    "        self.conv2 = nnx.Conv(32, 64, kernel_size=(3, 3), rngs=rngs)\n",
    "        self.linear1 = nnx.Linear(6*7*64, self.hidden_dim, rngs=rngs)\n",
    "        self.linear2 = nnx.Linear(self.hidden_dim, self.embedding_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, encoded_state_batch: jax.Array):\n",
    "        x = self._state_to_array(encoded_state_batch)\n",
    "        x = x[..., None]  # Add channel dimension\n",
    "        x = nnx.relu(self.conv1(x))\n",
    "        x = nnx.relu(self.conv2(x))\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten while preserving batch dimension\n",
    "        x = nnx.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "state_embedder = Connect4StateEmbedder(rngs=nnx.Rngs(0))\n",
    "\n",
    "print(state_embedder(trajectories[0].states[:1])[:,:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b11059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06664277  0.10936882 -0.18915226  0.08173456 -0.07859723]]\n"
     ]
    }
   ],
   "source": [
    "class Connect4ActionEmbedder(nnx.Module):\n",
    "    embedding_dim: int = 64\n",
    "    num_actions: int = 7\n",
    "\n",
    "    def __init__(self, *, rngs: nnx.Rngs):\n",
    "        self.embedding = nnx.Embed(num_embeddings=self.num_actions, features=self.embedding_dim, rngs=rngs)\n",
    "\n",
    "    def __call__(self, action: jax.Array) -> jax.Array:\n",
    "        # Ensure action is 0-indexed\n",
    "        action = action - 1\n",
    "        return self.embedding(action)\n",
    "    \n",
    "    def all_action_embeddings(self):\n",
    "        return self(jnp.arange(1,self.num_actions+1))\n",
    "\n",
    "action_embedder = Connect4ActionEmbedder(rngs=nnx.Rngs(0))\n",
    "\n",
    "\n",
    "print(action_embedder(trajectories[0].actions[:1])[:,:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21b1d2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [-0.0733178  -0.04830146 -0.0082891  -0.00399575  0.04669977 -0.08175676\n",
      "  -0.01695381]]\n",
      "\n",
      "probs:\n",
      "[[0.14285715 0.14285715 0.14285715 0.14285715 0.14285715 0.14285715\n",
      "  0.14285715]\n",
      " [0.13621384 0.13966438 0.14536598 0.14599143 0.15358336 0.13506916\n",
      "  0.14411187]]\n"
     ]
    }
   ],
   "source": [
    "class StateToActionModel(nnx.Module):\n",
    "    state_embedder: Connect4StateEmbedder\n",
    "    action_embedder: Connect4ActionEmbedder\n",
    "\n",
    "    embedding_dim: int = 64\n",
    "    num_actions: int = 7\n",
    "\n",
    "    def __init__(self, state_embedder: Connect4StateEmbedder, action_embedder: Connect4ActionEmbedder, *, rngs: nnx.Rngs):\n",
    "        self.state_embedder = state_embedder\n",
    "        self.action_embedder = action_embedder\n",
    "\n",
    "    def __call__(self, state: jax.Array) -> jax.Array:\n",
    "        return self.logits(state)\n",
    "\n",
    "    def logits(self, state_batch: jax.Array) -> jax.Array:\n",
    "        state_embeddings = self.state_embedder(state_batch)\n",
    "        all_action_embeddings = self.action_embedder.all_action_embeddings()\n",
    "        logits = state_embeddings @ all_action_embeddings.T\n",
    "        return logits\n",
    "    \n",
    "    def probs(self, state_batch: jax.Array) -> jax.Array:\n",
    "        logits = self.logits(state_batch)\n",
    "        return jax.nn.softmax(logits)\n",
    "\n",
    "\n",
    "state_action_model = StateToActionModel(state_embedder, action_embedder, rngs=nnx.Rngs(0))\n",
    "\n",
    "logits = state_action_model.logits(state_batch[:2])\n",
    "probs = state_action_model.probs(state_batch[:2])\n",
    "\n",
    "print(f'logits:\\n{logits}')\n",
    "print(f'\\nprobs:\\n{probs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d7637b",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "267c5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = nnx.Optimizer(state_embedder, optax.adamw(learning_rate, momentum))\n",
    "metrics = nnx.MultiMetric(accuracy=nnx.metrics.Accuracy(), loss=nnx.metrics.Average('loss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_fn(model: Connect4StateEmbedder, batch):\n",
    "#   logits = model(batch['state'])\n",
    "#   loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "#     logits=logits, labels=batch['action']\n",
    "#   ).mean()\n",
    "#   return loss, logits\n",
    "\n",
    "# @nnx.jit\n",
    "# def train_step(model: Connect4StateEmbedder, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "#   \"\"\"Train for a single step.\"\"\"\n",
    "#   grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "#   (loss, logits), grads = grad_fn(model, batch)\n",
    "#   metrics.update(loss=loss, logits=logits, labels=batch['action'])  # In-place updates.\n",
    "#   optimizer.update(grads)  # In-place updates.\n",
    "\n",
    "# @nnx.jit\n",
    "# def eval_step(model: Connect4StateEmbedder, metrics: nnx.MultiMetric, batch):\n",
    "#   loss, logits = loss_fn(model, batch)\n",
    "#   metrics.update(loss=loss, logits=logits, labels=batch['action'])  # In-place updates.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8d5947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(1.94158, dtype=float32),\n",
       " Array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.07331781, -0.04830145, -0.0082891 , -0.00399575,  0.04669978,\n",
       "         -0.08175675, -0.01695381]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@nnx.jit\n",
    "def l2_loss(model, alpha=0.001):\n",
    "    loss = sum(\n",
    "        (alpha * (w ** 2).sum()) \n",
    "        for w in jax.tree.leaves(nnx.state(model, nnx.Param))\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "@nnx.jit\n",
    "def loss_fn_2(state_embedder: Connect4StateEmbedder, action_embedder: Connect4ActionEmbedder, batch, l2_weight: float = 1e-4):\n",
    "    state_embeddings = state_embedder(batch['state'])\n",
    "    all_action_embeddings = action_embedder.all_action_embeddings()\n",
    "    logits = state_embeddings @ all_action_embeddings.T\n",
    "    # labels = jax.nn.one_hot(batch['action']-1, num_classes=7)\n",
    "    labels = batch['action']-1\n",
    "    data_loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=labels).mean()\n",
    "\n",
    "    state_embedder_l2 = l2_loss(state_embedder)\n",
    "    action_embedder_l2 = l2_loss(action_embedder)\n",
    "    \n",
    "    param_loss = l2_weight * (state_embedder_l2 + action_embedder_l2)\n",
    "\n",
    "    total_loss = data_loss + param_loss\n",
    "    return total_loss, logits\n",
    "\n",
    "loss_fn_2(state_embedder, action_embedder, batch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae318f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(state_embedder: Connect4StateEmbedder, action_embedder: Connect4ActionEmbedder, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  grad_fn = nnx.value_and_grad(loss_fn_2, has_aux=True)\n",
    "  (loss, logits), grads = grad_fn(state_embedder, action_embedder, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['action']-1)  # In-place updates.\n",
    "  optimizer.update(grads)  # In-place updates.\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(state_embedder: Connect4StateEmbedder, action_embedder: Connect4ActionEmbedder, metrics: nnx.MultiMetric, batch):\n",
    "  loss, logits = loss_fn_2(state_embedder, action_embedder, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['action'])  # In-place updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "  'train_loss': [],\n",
    "  'train_accuracy': [],\n",
    "  'test_loss': [],\n",
    "  'test_accuracy': [],\n",
    "}\n",
    "\n",
    "train_steps = 10000\n",
    "eval_every = 200\n",
    "batch_size = 32\n",
    "\n",
    "# TODO: How do we stream a bunch of different batches?\n",
    "# train_batches = [(i, batch) for i in range(2000)]\n",
    "# test_batches = [(i, batch) for i in range(100)]\n",
    "\n",
    "#train_batches = [(i, batch_repeated) for i in range(2000)]\n",
    "#test_batches = [(i, batch_repeated) for i in range(100)]\n",
    "\n",
    "train_batches = [(i, batch_full) for i in range(2000)]\n",
    "test_batches = [(i, batch_full) for i in range(100)]\n",
    "\n",
    "\n",
    "# for step, batch in enumerate(train_ds.as_numpy_iterator()):\n",
    "for step, batch in train_batches:\n",
    "  # Run the optimization for one step and make a stateful update to the following:\n",
    "  # - The train state's model parameters\n",
    "  # - The optimizer state\n",
    "  # - The training loss and accuracy batch metrics\n",
    "  # with jax.disable_jit():\n",
    "  #   train_step(state_embedder, action_embedder, optimizer, metrics, batch)\n",
    "  train_step(state_embedder, action_embedder, optimizer, metrics, batch)\n",
    "\n",
    "  if step > 0 and (step % eval_every == 0 or step == train_steps - 1):  # One training epoch has passed.\n",
    "    # Log the training metrics.\n",
    "    for metric, value in metrics.compute().items():  # Compute the metrics.\n",
    "      metrics_history[f'train_{metric}'].append(value)  # Record the metrics.\n",
    "    metrics.reset()  # Reset the metrics for the test set.\n",
    "\n",
    "    # Compute the metrics on the test set after each training epoch.\n",
    "    for _, test_batch in test_batches:\n",
    "      eval_step(state_embedder, action_embedder, metrics, test_batch)\n",
    "\n",
    "    # Log the test metrics.\n",
    "    for metric, value in metrics.compute().items():\n",
    "      metrics_history[f'test_{metric}'].append(value)\n",
    "    metrics.reset()  # Reset the metrics for the next training epoch.\n",
    "\n",
    "    print(\n",
    "      f\"[train] step: {step}, \"\n",
    "      f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
    "      f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\"\n",
    "    )\n",
    "    # print(\n",
    "    #   f\"[test] step: {step}, \"\n",
    "    #   f\"loss: {metrics_history['test_loss'][-1]}, \"\n",
    "    #   f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\"\n",
    "    # )\n",
    "\n",
    "\n",
    "## Outputs with embedding normalization.\n",
    "# [train] step: 200, loss: 1.1590911149978638, accuracy: 100.0\n",
    "# [train] step: 400, loss: 1.1590913534164429, accuracy: 100.0\n",
    "# [train] step: 600, loss: 1.1590913534164429, accuracy: 100.0\n",
    "# [train] step: 800, loss: 1.1590913534164429, accuracy: 100.0\n",
    "# [train] step: 1000, loss: 1.1590913534164429, accuracy: 100.0\n",
    "# [train] step: 1199, loss: 1.1590930223464966, accuracy: 100.0\n",
    "# [train] step: 1200, loss: 1.159092903137207, accuracy: 100.0\n",
    "# [train] step: 1400, loss: 1.1590913534164429, accuracy: 100.0\n",
    "# [train] step: 1600, loss: 1.1590913534164429, accuracy: 100.0\n",
    "# [train] step: 1800, loss: 1.1590913534164429, accuracy: 100.0\n",
    "\n",
    "# logits: [[-0.12943102 -0.18300387 -0.31407255 -0.26985747 -0.03317889  0.8657205  -0.06745078]\n",
    "#          [-0.3108766  -0.11808072 -0.00877056 -0.12999986 -0.18233624 -0.03913596   0.86498916]]\n",
    "# probs: [[0.11739378 0.11127014 0.09760144 0.10201374 0.12925485 0.31756592  0.1249001 ]\n",
    "#         [0.09565745 0.11599759 0.12939627 0.1146232  0.10877853 0.12552617  0.31002077]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e7add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a23de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
