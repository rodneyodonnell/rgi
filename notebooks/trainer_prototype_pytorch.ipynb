{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1440ce-9dee-447c-93a5-65b8c7e889e3",
   "metadata": {},
   "source": [
    "# Trainer pytorch scratchpad\n",
    "\n",
    "Generate training data\n",
    "```\n",
    "python rgi/main.py --game connect4 --player1 random --player2 random --num_games 100 --save_trajectories\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf8ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3b522",
   "metadata": {},
   "source": [
    "# Load Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d0fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectories_glob: ../data/trajectories/connect4/*.trajectory.npy\n",
      "num_trajectories: 1100\n"
     ]
    }
   ],
   "source": [
    "# Load Trajectories (same as before)\n",
    "from rgi.core import trajectory\n",
    "\n",
    "game_name = \"connect4\"\n",
    "trajectories_glob = os.path.join(\"..\", \"data\", \"trajectories\", game_name, \"*.trajectory.npy\")\n",
    "trajectories = trajectory.load_trajectories(trajectories_glob)\n",
    "\n",
    "print(f'trajectories_glob: {trajectories_glob}')\n",
    "print(f'num_trajectories: {len(trajectories)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8071314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trajectory_steps: 22835\n"
     ]
    }
   ],
   "source": [
    "# Define trajectory NamedTuple and unroll_trajectory function (same as before)\n",
    "from typing import NamedTuple\n",
    "import numpy as np\n",
    "class TrajectoryStep(NamedTuple):\n",
    "    move_index: int\n",
    "    state: torch.Tensor\n",
    "    action: torch.Tensor\n",
    "    next_state: torch.Tensor\n",
    "    reward: torch.Tensor\n",
    "\n",
    "def fixup_reward(x): return (x+1) / 2\n",
    "\n",
    "def unroll_trajectory(encoded_trajectories: list[trajectory.EncodedTrajectory]):\n",
    "    for t in encoded_trajectories:\n",
    "        for i in range(t.length - 1):\n",
    "            # Convert states to writeable numpy arrays\n",
    "            state = np.array(t.states[i], dtype=np.float32)\n",
    "            next_state = np.array(t.states[i + 1], dtype=np.float32)\n",
    "            action = np.array(t.actions[i], dtype=np.int32)\n",
    "            reward = np.array(fixup_reward(t.final_rewards[0]), dtype=np.float32)\n",
    "                \n",
    "            yield TrajectoryStep(i, \n",
    "                                 torch.tensor(state, dtype=torch.float32),\n",
    "                                 torch.tensor(action, dtype=torch.int32),\n",
    "                                 torch.tensor(next_state, dtype=torch.float32),\n",
    "                                 torch.tensor(reward, dtype=torch.float32))\n",
    "\n",
    "all_trajectory_steps = list(unroll_trajectory(trajectories))\n",
    "print(f'num_trajectory_steps: {len(all_trajectory_steps)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dded9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile data loading code.\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Your slow code here\n",
    "all_trajectory_steps = list(unroll_trajectory(trajectories))\n",
    "\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('cumulative')\n",
    "stats.print_stats(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b168ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape:  torch.Size([22835, 43])\n",
      "action shape: torch.Size([22835])\n",
      "reward shape: torch.Size([22835])\n"
     ]
    }
   ],
   "source": [
    "# Prepare batches\n",
    "state_batch = torch.stack([t.state for t in all_trajectory_steps])\n",
    "action_batch = torch.stack([t.action for t in all_trajectory_steps])\n",
    "reward_batch = torch.stack([t.reward for t in all_trajectory_steps])\n",
    "batch_full = {'state': state_batch, 'action': action_batch, 'reward': reward_batch}\n",
    "\n",
    "print(f'state shape:  {batch_full[\"state\"].shape}')\n",
    "print(f'action shape: {batch_full[\"action\"].shape}')\n",
    "print(f'reward shape: {batch_full[\"reward\"].shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07df08c",
   "metadata": {},
   "source": [
    "# Save/Load in pytorch format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc0c16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "states = torch.stack([t.state for t in all_trajectory_steps])\n",
    "actions = torch.stack([t.action for t in all_trajectory_steps])\n",
    "next_states = torch.stack([t.next_state for t in all_trajectory_steps])\n",
    "rewards = torch.stack([t.reward for t in all_trajectory_steps])\n",
    "\n",
    "# Save processed data\n",
    "torch.save({\n",
    "    'states': states,\n",
    "    'actions': actions,\n",
    "    'next_states': next_states,\n",
    "    'rewards': rewards\n",
    "}, 'processed_trajectories.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d7266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = torch.load('processed_trajectories.pt', weights_only=True)\n",
    "reloaded_states = loaded_data['states']\n",
    "reloaded_actions = loaded_data['actions']\n",
    "reloaded_next_states = loaded_data['next_states']\n",
    "reloaded_rewards = loaded_data['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9042317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, states, actions, next_states, rewards):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.next_states = next_states\n",
    "        self.rewards = rewards\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.states[idx], self.actions[idx], \n",
    "                self.next_states[idx], self.rewards[idx])\n",
    "\n",
    "# Create dataset\n",
    "dataset = TrajectoryDataset(states, actions, next_states, rewards)\n",
    "\n",
    "# Use DataLoader for efficient batching\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d96bcf",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "476b277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect4StateEmbedder(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(64 * 6 * 7, self.hidden_dim)\n",
    "        self.linear2 = nn.Linear(self.hidden_dim, self.embedding_dim)\n",
    "        \n",
    "    def _state_to_array(self, encoded_state_batch):\n",
    "        return encoded_state_batch[:, :-1].reshape(-1, 1, 6, 7)\n",
    "    \n",
    "    def forward(self, encoded_state_batch):\n",
    "        x = self._state_to_array(encoded_state_batch)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06cc7a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample states shape: torch.Size([2, 43])\n",
      "State embeddings shape: torch.Size([2, 64])\n",
      "First few values of embeddings:\n",
      "tensor([[ 0.0276,  0.0408,  0.0303, -0.0146, -0.0464],\n",
      "        [ 0.0230,  0.0380,  0.0300, -0.0109, -0.0419]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def test_state_embedder():\n",
    "    state_embedder = Connect4StateEmbedder().to(device)\n",
    "    sample_states = state_batch[:2].to(device)\n",
    "    embeddings = state_embedder(sample_states)\n",
    "    print(\"Sample states shape:\", sample_states.shape)\n",
    "    print(\"State embeddings shape:\", embeddings.shape)\n",
    "    print(\"First few values of embeddings:\")\n",
    "    print(embeddings[:, :5])\n",
    "\n",
    "test_state_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2170ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect4ActionEmbedder(nn.Module):\n",
    "    def __init__(self, embedding_dim=64, num_actions=7):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.embedding = nn.Embedding(num_actions, embedding_dim)\n",
    "    \n",
    "    def forward(self, action):\n",
    "        return self.embedding(action - 1)\n",
    "    \n",
    "    def all_action_embeddings(self):\n",
    "        return self.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cabd04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action embeddings shape: torch.Size([1, 64])\n",
      "Action embeddings:\n",
      "tensor([[ 0.4400, -0.3875,  1.5108, -0.6908, -0.4308,  0.2181,  1.7117,  1.6171,\n",
      "          0.4790,  1.6018,  0.1761,  0.5400,  0.4086,  0.6683, -0.5456,  0.3425,\n",
      "         -0.2177, -0.1389,  0.2651, -0.6244,  2.1062, -0.2677,  0.4823, -0.2823,\n",
      "          0.2660, -0.0082,  1.6424, -1.8429,  1.4423,  0.6335,  0.3741, -0.4514,\n",
      "          2.2383,  0.1583,  0.2759, -0.7155,  0.1515,  1.5209, -0.6984, -1.1295,\n",
      "         -0.5943,  1.7510, -0.5253,  0.8532,  0.6825, -0.1523, -0.5436,  0.7105,\n",
      "          0.2030, -0.2270, -0.6880, -0.7623, -0.4580,  0.3234, -0.0067, -0.9274,\n",
      "         -0.2421,  0.0236, -1.3549, -0.1059,  0.7561,  1.5237,  0.2885, -0.1838]],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n",
      "All action embeddings:\n",
      "tensor([[ 0.0677, -1.0600, -0.0900,  0.8930, -1.0142],\n",
      "        [-1.3473,  0.3974,  2.2329,  1.0015, -0.7086],\n",
      "        [ 0.1829, -0.3556, -1.3620, -0.9318,  0.6255],\n",
      "        [-0.6195, -0.8287, -1.2327, -0.5364,  1.0767],\n",
      "        [ 1.8278, -0.2209,  1.8366, -0.6555, -0.9736],\n",
      "        [ 0.4400, -0.3875,  1.5108, -0.6908, -0.4308],\n",
      "        [ 0.6921,  0.8206, -1.2712, -0.0875,  0.4358]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# After defining Connect4ActionEmbedder\n",
    "def test_action_embedder():\n",
    "    action_embedder = Connect4ActionEmbedder().to(device)\n",
    "    sample_actions = action_batch[:1].to(device)\n",
    "    embeddings = action_embedder(sample_actions)\n",
    "    print(\"Action embeddings shape:\", embeddings.shape)\n",
    "    print(\"Action embeddings:\")\n",
    "    print(embeddings)\n",
    "    print(\"All action embeddings:\")\n",
    "    print(action_embedder.all_action_embeddings()[:, :5])\n",
    "\n",
    "test_action_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42cf779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel(nn.Module):\n",
    "    def __init__(self, state_embedder, action_embedder, embedding_dim=64, num_actions=7):\n",
    "        super().__init__()\n",
    "        self.state_embedder = state_embedder\n",
    "        self.action_embedder = action_embedder\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.reward_head = nn.Linear(self.embedding_dim, 1)\n",
    "    \n",
    "    def action_logits(self, state_batch):\n",
    "        state_embeddings = self.state_embedder(state_batch)\n",
    "        all_action_embeddings = self.action_embedder.all_action_embeddings()\n",
    "        logits = torch.matmul(state_embeddings, all_action_embeddings.t())\n",
    "        return logits\n",
    "    \n",
    "    def action_probs(self, state_batch):\n",
    "        logits = self.action_logits(state_batch)\n",
    "        return torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    def reward_pred(self, state_batch):\n",
    "        state_embeddings = self.state_embedder(state_batch)\n",
    "        return self.reward_head(state_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8548365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action logits shape: torch.Size([2, 7])\n",
      "Action logits:\n",
      "tensor([[-0.6928, -0.2426,  0.8710,  0.0857, -0.4242, -0.4686, -0.2346],\n",
      "        [-0.6637, -0.2830,  0.8562,  0.0995, -0.4559, -0.4721, -0.2352]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n",
      "\n",
      "Action probabilities:\n",
      "tensor([[0.0732, 0.1148, 0.3496, 0.1594, 0.0957, 0.0916, 0.1157],\n",
      "        [0.0760, 0.1112, 0.3475, 0.1630, 0.0936, 0.0921, 0.1167]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "Reward predictions:\n",
      "tensor([[0.0074],\n",
      "        [0.0081]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# After defining PredictionModel\n",
    "def test_prediction_model():\n",
    "    state_embedder = Connect4StateEmbedder().to(device)\n",
    "    action_embedder = Connect4ActionEmbedder().to(device)\n",
    "    prediction_model = PredictionModel(state_embedder, action_embedder).to(device)\n",
    "    \n",
    "    sample_states = state_batch[:2].to(device)\n",
    "    \n",
    "    action_logits = prediction_model.action_logits(sample_states)\n",
    "    action_probs = prediction_model.action_probs(sample_states)\n",
    "    reward_pred = prediction_model.reward_pred(sample_states)\n",
    "    \n",
    "    print(\"Action logits shape:\", action_logits.shape)\n",
    "    print(\"Action logits:\")\n",
    "    print(action_logits)\n",
    "    print(\"\\nAction probabilities:\")\n",
    "    print(action_probs)\n",
    "    print(\"\\nReward predictions:\")\n",
    "    print(reward_pred)\n",
    "\n",
    "test_prediction_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a54cb9",
   "metadata": {},
   "source": [
    "# Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55bea013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fn(prediction_model, batch, l2_weight=1e-4):\n",
    "    action_logits = prediction_model.action_logits(batch['state'])\n",
    "    action_labels = (batch['action'] - 1).long()  # Convert to Long type\n",
    "    action_data_loss = nn.functional.cross_entropy(action_logits, action_labels)\n",
    "    \n",
    "    reward_pred = prediction_model.reward_pred(batch['state']).squeeze()\n",
    "    reward_labels = batch['reward']\n",
    "    reward_data_loss = nn.functional.mse_loss(reward_pred, reward_labels)\n",
    "    \n",
    "    l2_loss = sum((p ** 2).sum() for p in prediction_model.parameters())\n",
    "    \n",
    "    total_loss = action_data_loss + reward_data_loss + l2_weight * l2_loss\n",
    "    return total_loss, (action_logits, reward_pred)\n",
    "\n",
    "# Training function\n",
    "def train_step(prediction_model, optimizer, batch):\n",
    "    prediction_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss, (logits, reward_pred) = loss_fn(prediction_model, batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), logits, reward_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6babfb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "# Prepare dataset\n",
    "class TrajectoryDataset(data.Dataset):\n",
    "    def __init__(self, states, actions, rewards):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx], self.actions[idx], self.rewards[idx]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TrajectoryDataset(state_batch, action_batch, reward_batch)\n",
    "batch_size = 64  # Adjust this value based on your GPU memory\n",
    "dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Main training loop\n",
    "def train_model(print_logits=False, num_epochs=10):\n",
    "    state_embedder = Connect4StateEmbedder().to(device)\n",
    "    action_embedder = Connect4ActionEmbedder().to(device)\n",
    "    prediction_model = PredictionModel(state_embedder, action_embedder).to(device)\n",
    "    optimizer = optim.Adam(prediction_model.parameters(), lr=0.0005)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for i, (states, actions, rewards) in enumerate(dataloader):\n",
    "            states, actions, rewards = states.to(device), actions.to(device), rewards.to(device)\n",
    "            batch = {'state': states, 'action': actions, 'reward': rewards}\n",
    "            \n",
    "            loss, (logits, reward_pred) = loss_fn(prediction_model, batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        if print_logits:\n",
    "            for j in range(4):\n",
    "                state = states[j].unsqueeze(0)\n",
    "                action_probs = prediction_model.action_probs(state)\n",
    "                reward_pred = prediction_model.reward_pred(state).item()\n",
    "                reward_true = rewards[j].item()\n",
    "                print(j, f'r={reward_true:.4f} p={reward_pred:.4f}', action_probs.cpu().detach().numpy())\n",
    "            print()\n",
    "    \n",
    "    return prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2e99736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/357], Loss: 2.2429\n",
      "Epoch [1/10], Step [200/357], Loss: 2.2272\n",
      "Epoch [1/10], Step [300/357], Loss: 2.2235\n",
      "Epoch [1/10], Average Loss: 2.2546\n",
      "0 r=1.0000 p=0.6442 [[0.11464751 0.13339584 0.12322022 0.15932459 0.16929626 0.16126208 0.13885349]]\n",
      "1 r=1.0000 p=0.5785 [[0.10394179 0.12067673 0.12600508 0.17570962 0.16703825 0.1559565  0.15067205]]\n",
      "2 r=0.0000 p=0.5148 [[0.14041291 0.13038336 0.12101714 0.15320817 0.15778473 0.1736262  0.12356753]]\n",
      "3 r=1.0000 p=0.5808 [[0.09953909 0.13835198 0.13823558 0.17376362 0.14622344 0.16698591 0.1369004 ]]\n",
      "\n",
      "Epoch [2/10], Step [100/357], Loss: 2.2195\n",
      "Epoch [2/10], Step [200/357], Loss: 2.2243\n",
      "Epoch [2/10], Step [300/357], Loss: 2.2278\n",
      "Epoch [2/10], Average Loss: 2.2082\n",
      "0 r=1.0000 p=0.6067 [[0.17434004 0.15488389 0.16499685 0.13464737 0.01110733 0.22378612 0.13623843]]\n",
      "1 r=1.0000 p=1.0207 [[0.17595111 0.18077828 0.17725362 0.01211655 0.11814594 0.17312568 0.16262877]]\n",
      "2 r=0.0000 p=0.7469 [[0.12633634 0.13760516 0.19996881 0.14245827 0.12308919 0.13516581 0.13537642]]\n",
      "3 r=1.0000 p=0.5482 [[0.14139453 0.13746317 0.16099097 0.135116   0.13212937 0.15790293 0.13500302]]\n",
      "\n",
      "Epoch [3/10], Step [100/357], Loss: 2.1668\n",
      "Epoch [3/10], Step [200/357], Loss: 2.1832\n",
      "Epoch [3/10], Step [300/357], Loss: 2.1905\n",
      "Epoch [3/10], Average Loss: 2.1808\n",
      "0 r=1.0000 p=0.5964 [[0.16895898 0.15574417 0.13332565 0.13130549 0.13554382 0.14082198 0.13429995]]\n",
      "1 r=0.0000 p=0.4607 [[0.18210077 0.10615245 0.13784422 0.12823564 0.12281071 0.13963895 0.18321732]]\n",
      "2 r=1.0000 p=0.7479 [[0.21511436 0.15961668 0.18794833 0.14480357 0.13074264 0.00406685 0.15770759]]\n",
      "3 r=1.0000 p=0.6211 [[0.08782205 0.03048345 0.12704958 0.23432568 0.13395435 0.2392603  0.14710458]]\n",
      "\n",
      "Epoch [4/10], Step [100/357], Loss: 2.1243\n",
      "Epoch [4/10], Step [200/357], Loss: 2.1641\n",
      "Epoch [4/10], Step [300/357], Loss: 2.1080\n",
      "Epoch [4/10], Average Loss: 2.1476\n",
      "0 r=0.0000 p=0.4977 [[0.16609462 0.17347847 0.16427875 0.1230664  0.13271381 0.09852547 0.14184251]]\n",
      "1 r=1.0000 p=0.4975 [[0.139052   0.15466207 0.14651842 0.1543474  0.13663816 0.13430683 0.13447508]]\n",
      "2 r=1.0000 p=0.4982 [[0.12871946 0.12842478 0.1658008  0.15041219 0.14396496 0.13888289 0.1437949 ]]\n",
      "3 r=1.0000 p=0.5864 [[0.14506395 0.13707492 0.16749963 0.14182305 0.12333483 0.16445604 0.12074756]]\n",
      "\n",
      "Epoch [5/10], Step [100/357], Loss: 2.1460\n",
      "Epoch [5/10], Step [200/357], Loss: 2.1711\n",
      "Epoch [5/10], Step [300/357], Loss: 2.1128\n",
      "Epoch [5/10], Average Loss: 2.1086\n",
      "0 r=1.0000 p=0.6016 [[0.12898126 0.14353006 0.15332642 0.13044551 0.13142163 0.15942463 0.15287048]]\n",
      "1 r=0.0000 p=0.1062 [[0.16170739 0.11697548 0.11211458 0.14612357 0.14345413 0.13279957 0.18682528]]\n",
      "2 r=1.0000 p=0.5396 [[0.13081577 0.15362139 0.16938211 0.1255539  0.11276071 0.14551319 0.16235289]]\n",
      "3 r=0.0000 p=0.0528 [[0.11970056 0.05489936 0.22947685 0.11231823 0.16424951 0.19303392 0.12632155]]\n",
      "\n",
      "Epoch [6/10], Step [100/357], Loss: 2.0924\n",
      "Epoch [6/10], Step [200/357], Loss: 2.1115\n",
      "Epoch [6/10], Step [300/357], Loss: 2.1307\n",
      "Epoch [6/10], Average Loss: 2.0602\n",
      "0 r=0.0000 p=0.3840 [[0.2341519  0.15908447 0.14277372 0.15989786 0.05913248 0.0734355  0.1715241 ]]\n",
      "1 r=0.0000 p=0.0977 [[0.14245395 0.10101927 0.17089695 0.18927231 0.10659179 0.1539319  0.13583378]]\n",
      "2 r=0.0000 p=0.5584 [[0.11417486 0.11652748 0.11615016 0.18505196 0.18347731 0.11004364 0.17457457]]\n",
      "3 r=0.0000 p=0.4858 [[0.09594695 0.13823242 0.08772677 0.20005275 0.15415615 0.09195189 0.23193312]]\n",
      "\n",
      "Epoch [7/10], Step [100/357], Loss: 1.9559\n",
      "Epoch [7/10], Step [200/357], Loss: 2.0830\n",
      "Epoch [7/10], Step [300/357], Loss: 2.0216\n",
      "Epoch [7/10], Average Loss: 2.0039\n",
      "0 r=1.0000 p=0.8780 [[0.21172182 0.11270766 0.14671446 0.09166256 0.29497322 0.04926073 0.09295951]]\n",
      "1 r=1.0000 p=0.6640 [[0.2081398  0.15031968 0.11624477 0.13176158 0.08851656 0.13361137 0.17140616]]\n",
      "2 r=0.0000 p=0.0415 [[0.08751141 0.29037553 0.4559837  0.07463195 0.02599161 0.02488836 0.04061743]]\n",
      "3 r=0.0000 p=0.4667 [[0.15015134 0.09614305 0.16291817 0.17060119 0.14415832 0.1513655  0.1246624 ]]\n",
      "\n",
      "Epoch [8/10], Step [100/357], Loss: 1.9707\n",
      "Epoch [8/10], Step [200/357], Loss: 1.7796\n",
      "Epoch [8/10], Step [300/357], Loss: 1.9975\n",
      "Epoch [8/10], Average Loss: 1.9341\n",
      "0 r=1.0000 p=1.1702 [[0.08891497 0.06688634 0.15198538 0.05378974 0.3696502  0.04394705 0.22482635]]\n",
      "1 r=1.0000 p=0.7055 [[0.24063373 0.00096078 0.20780571 0.08724449 0.0753675  0.20666544 0.1813224 ]]\n",
      "2 r=1.0000 p=0.8950 [[0.14716959 0.00285895 0.14636236 0.10112217 0.11229546 0.19696121 0.29323027]]\n",
      "3 r=0.0000 p=-0.1043 [[0.145651   0.03275208 0.10674988 0.0147548  0.11448582 0.03410848 0.55149794]]\n",
      "\n",
      "Epoch [9/10], Step [100/357], Loss: 1.7381\n",
      "Epoch [9/10], Step [200/357], Loss: 1.8938\n",
      "Epoch [9/10], Step [300/357], Loss: 1.8909\n",
      "Epoch [9/10], Average Loss: 1.8521\n",
      "0 r=1.0000 p=0.5367 [[0.10827218 0.21122214 0.12310272 0.14332823 0.15392162 0.12341722 0.13673592]]\n",
      "1 r=0.0000 p=0.1664 [[2.8294147e-04 3.5621107e-01 2.7652684e-01 4.2416301e-02 2.0122384e-01 1.0791557e-02 1.1254751e-01]]\n",
      "2 r=0.0000 p=0.1377 [[0.09753805 0.04970798 0.17194587 0.39781362 0.15117809 0.08731388 0.04450246]]\n",
      "3 r=0.0000 p=0.2202 [[0.05524918 0.14694843 0.18374233 0.06454696 0.05931915 0.35224685 0.1379471 ]]\n",
      "\n",
      "Epoch [10/10], Step [100/357], Loss: 1.6481\n",
      "Epoch [10/10], Step [200/357], Loss: 1.7595\n",
      "Epoch [10/10], Step [300/357], Loss: 1.8222\n",
      "Epoch [10/10], Average Loss: 1.7708\n",
      "0 r=1.0000 p=0.6133 [[0.19610325 0.10503798 0.1342942  0.07161627 0.03502524 0.2512586  0.20666453]]\n",
      "1 r=0.0000 p=0.0883 [[0.00887123 0.04717347 0.03129928 0.891822   0.00172923 0.00659328 0.01251149]]\n",
      "2 r=1.0000 p=0.6757 [[0.0978752  0.06379396 0.17167355 0.10939027 0.23780224 0.1673716  0.1520932 ]]\n",
      "3 r=0.0000 p=0.4833 [[0.16683507 0.13572186 0.13753784 0.1791103  0.1322244  0.11206559 0.13650493]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "prediction_model = train_model(print_logits=True, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aa5dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(prediction_model.state_dict(), 'connect4_prediction_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "843dc87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionModel(\n",
       "  (state_embedder): Connect4StateEmbedder(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear1): Linear(in_features=2688, out_features=256, bias=True)\n",
       "    (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (action_embedder): Connect4ActionEmbedder(\n",
       "    (embedding): Embedding(7, 64)\n",
       "  )\n",
       "  (reward_head): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = PredictionModel(Connect4StateEmbedder(), Connect4ActionEmbedder())\n",
    "loaded_model.load_state_dict(torch.load('connect4_prediction_model.pth'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b305d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move 0:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1.]], device='cuda:0') 0.5605407953262329 [[0.1638865  0.15204294 0.12782744 0.1432951  0.12901308 0.1448501  0.13908486]]\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1.]], device='cuda:0') 0.5605407953262329 [[0.1638865  0.15204294 0.12782744 0.1432951  0.12901308 0.1448501  0.13908486]]\n"
     ]
    }
   ],
   "source": [
    "# Test the loaded model\n",
    "from rgi.games import connect4\n",
    "import numpy as np\n",
    "\n",
    "game = connect4.Connect4Game()\n",
    "serializer = connect4.Connect4Serializer()\n",
    "\n",
    "print('Move 0:')\n",
    "s_0 = game.initial_state()\n",
    "state_array = serializer.state_to_jax_array(game, s_0)\n",
    "writeable_state = np.array(state_array, dtype=np.float32)  # Create a writeable copy\n",
    "j_0 = torch.tensor(writeable_state, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "print(j_0, prediction_model.reward_pred(j_0).item(), prediction_model.action_probs(j_0).cpu().detach().numpy())\n",
    "\n",
    "# Load the model and move it to GPU\n",
    "loaded_model = PredictionModel(Connect4StateEmbedder(), Connect4ActionEmbedder())\n",
    "loaded_model.load_state_dict(torch.load('connect4_prediction_model.pth'))\n",
    "loaded_model = loaded_model.to(device)  # Move the loaded model to GPU\n",
    "loaded_model.eval()\n",
    "\n",
    "print(j_0, loaded_model.reward_pred(j_0).item(), loaded_model.action_probs(j_0).cpu().detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
