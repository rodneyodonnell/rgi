{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1440ce-9dee-447c-93a5-65b8c7e889e3",
   "metadata": {},
   "source": [
    "# Pytorch scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bbecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from typing import Any, Optional, Sequence, Type, TypeVar\n",
    "from typing import override\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "\n",
    "from rgi.core import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c550bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgi.games import connect4\n",
    "\n",
    "# reimport connect4\n",
    "importlib.reload(connect4)\n",
    "GameState = connect4.GameState\n",
    "BatchGameState = connect4.BatchGameState\n",
    "Action = connect4.Action\n",
    "BatchAction = connect4.BatchAction\n",
    "PlayerId = connect4.PlayerId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df5e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect4Scratch(connect4.Connect4Game):\n",
    "\n",
    "    @override\n",
    "    def next_state(self, game_state: GameState, action: Action) -> GameState:\n",
    "        \"\"\"Find the lowest empty row in the selected column and return the updated game state.\"\"\"\n",
    "        if action not in self.legal_actions(game_state):\n",
    "            raise ValueError(\n",
    "                f\"Invalid move: Invalid column '{action}' no in {self._all_column_ids}\"\n",
    "            )\n",
    "\n",
    "        for row in range(1, self.height + 1):\n",
    "            if (row, action) not in game_state.board:\n",
    "                new_board = game_state.board.set((row, action), game_state.current_player)\n",
    "                winner = self._calculate_winner(\n",
    "                    new_board, action, row, game_state.current_player\n",
    "                )\n",
    "                next_player: PlayerId = 2 if game_state.current_player == 1 else 1\n",
    "                return GameState(\n",
    "                    board=new_board, current_player=next_player, winner=winner\n",
    "                )\n",
    "\n",
    "        raise ValueError(\"Invalid move: column is full\")\n",
    "\n",
    "    def _calculate_winner(\n",
    "        self, board: torch.Tensor, col: int, row: int, player: PlayerId\n",
    "    ) -> Optional[PlayerId]:\n",
    "        \"\"\"Check if the last move made at (row, col) by 'player' wins the game.\"\"\"\n",
    "        directions = [\n",
    "            ((1, 0), (-1, 0)),  # Vertical\n",
    "            ((0, 1), (0, -1)),  # Horizontal\n",
    "            ((1, 1), (-1, -1)),  # Diagonal /\n",
    "            ((1, -1), (-1, 1)),  # Diagonal \\\n",
    "        ]\n",
    "\n",
    "        def count_in_direction(delta_row: int, delta_col: int) -> int:\n",
    "            \"\"\"Count consecutive pieces in one direction.\"\"\"\n",
    "            count = 0\n",
    "            current_row, current_col = row + delta_row, col + delta_col\n",
    "            while 1 <= current_row <= self.height and 1 <= current_col <= self.width:\n",
    "                if board.get((current_row, current_col)) == player:\n",
    "                    count += 1\n",
    "                    current_row += delta_row\n",
    "                    current_col += delta_col\n",
    "                else:\n",
    "                    break\n",
    "            return count\n",
    "\n",
    "        for (delta_row1, delta_col1), (delta_row2, delta_col2) in directions:\n",
    "            consecutive_count = (\n",
    "                count_in_direction(delta_row1, delta_col1)\n",
    "                + count_in_direction(delta_row2, delta_col2)\n",
    "                + 1  # Include the current piece\n",
    "            )\n",
    "            if consecutive_count >= self.connect_length:\n",
    "                return player\n",
    "\n",
    "        return None  # No winner yet\n",
    "\n",
    "    @override\n",
    "    def is_terminal(self, game_state: GameState) -> bool:\n",
    "        if game_state.winner is not None:\n",
    "            return True\n",
    "        return all((self.height, col) in game_state.board for col in self._all_column_ids)\n",
    "\n",
    "    @override\n",
    "    def reward(self, game_state: GameState, player_id: PlayerId) -> float:\n",
    "        if game_state.winner == player_id:\n",
    "            return 1.0\n",
    "        elif game_state.winner is not None:\n",
    "            return -1.0\n",
    "        return 0.0\n",
    "\n",
    "    @override\n",
    "    def pretty_str(self, game_state: GameState) -> str:\n",
    "        return (\n",
    "            \"\\n\".join(\n",
    "                \"|\"\n",
    "                + \"|\".join(\n",
    "                    \" ●○\"[game_state.board.get((row, col), 0)]\n",
    "                    for col in self._all_column_ids\n",
    "                )\n",
    "                + \"|\"\n",
    "                for row in reversed(\n",
    "                    self._all_row_ids\n",
    "                )  # Start from the top row and work down\n",
    "            )\n",
    "            + \"\\n+\"\n",
    "            + \"-+\" * self.width\n",
    "        )\n",
    "\n",
    "    def parse_board(self, board_str: str, current_player: PlayerId) -> GameState:\n",
    "        \"\"\"Parses the output of pretty_str into a GameState.\"\"\"\n",
    "        rows = board_str.strip().split(\"\\n\")[:-1]  # Skip the bottom border row\n",
    "        board: Map[TPosition, int] = Map()\n",
    "        for r, row in enumerate(reversed(rows), start=1):\n",
    "            row_cells = row.strip().split(\"|\")[1:-1]  # Extract cells between borders\n",
    "            for c, cell in enumerate(row_cells, start=1):\n",
    "                if cell == \"●\":\n",
    "                    board = board.set((r, c), 1)  # Player 1\n",
    "                elif cell == \"○\":\n",
    "                    board = board.set((r, c), 2)  # Player 2\n",
    "        return GameState(board=board, current_player=current_player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f463f9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 5, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Connect4Scratch()\n",
    "initial_state = g.initial_state()\n",
    "\n",
    "assert g.current_player_id(initial_state) == 1\n",
    "assert g.all_actions() == (1, 2, 3, 4, 5, 6, 7)\n",
    "# assert g.legal_actions(initial_state) == (2, 3, 4, 5, 7)\n",
    "\n",
    "b = initial_state.board\n",
    "b[0, 0] = 1\n",
    "b[0, 5] = -1\n",
    "# assert g.legal_actions(initial_state) == (2, 3, 4, 5, 7)\n",
    "\n",
    "g.legal_actions(initial_state)\n",
    "\n",
    "    # @override\n",
    "    # def legal_actions(self, game_state: GameState) -> Sequence[Action]:\n",
    "    #     return ((game_state.board[0] == 0).nonzero().squeeze()+1).tolist()\n",
    "\n",
    "tuple(((b[0] == 0).nonzero().squeeze()+1).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16bbf6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 2,  4,  6,  8, 10]])\n",
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 2,  4,  6,  8, 10]])\n",
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 2,  4,  6,  8, 10]])\n",
      "tensor([1., 2., 3., 4., 5.])\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
      "        [ 2.,  4.,  6.,  8., 10.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15584/3925812895.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(torch.stack([torch.tensor(value) for value in values_torch]))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3] at entry 0 and [2] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mtensor(value) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values_float]))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mtensor(value) \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values_float_2d]))\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalues_ragged\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3] at entry 0 and [2] at entry 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "values_int = [1, 2, 3, 4, 5]\n",
    "values_int_2d = [[1, 2, 3, 4, 5], [2,4,6,8,10]]\n",
    "values_np = [np.array(values_int), np.array(values_int)*2]\n",
    "values_torch = [torch.tensor(values_int), torch.tensor(values_int)*2]\n",
    "values_float = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "values_float_2d = [[1.0, 2.0, 3.0, 4.0, 5.0], [2.0,4.0,6.0,8.0,10.0]]\n",
    "\n",
    "print(torch.stack([torch.tensor(value) for value in values_int]))\n",
    "print(torch.stack([torch.tensor(value) for value in values_int_2d]))\n",
    "print(torch.stack([torch.tensor(value) for value in values_np]))\n",
    "print(torch.stack([torch.tensor(value) for value in values_torch]))\n",
    "print(torch.stack([torch.tensor(value) for value in values_float]))\n",
    "print(torch.stack([torch.tensor(value) for value in values_float_2d]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "479d4891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 2, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 2, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board_size = 8\n",
    "board = torch.zeros((board_size, board_size), dtype=torch.int8)\n",
    "mid = board_size // 2\n",
    "# board[mid - 1 : mid + 1, mid - 1 : mid + 1] = torch.tensor([[2, 1], [1, 2]], dtype=torch.int8)\n",
    "board[mid - 1, mid - 1] = 2\n",
    "board[mid - 1, mid] = 1\n",
    "board[mid, mid - 1] = 1\n",
    "board[mid, mid] = 2\n",
    "\n",
    "board\n",
    "\n",
    "    # @override\n",
    "    # def initial_state(self) -> OthelloState:\n",
    "    #     board = torch.zeros((self.board_size, self.board_size), dtype=torch.int8)\n",
    "    #     mid = self.board_size // 2\n",
    "    #     board[mid - 1 : mid + 1, mid - 1 : mid + 1] = torch.tensor([[2, 1], [1, 2]], dtype=torch.int8)\n",
    "    #     return OthelloState(board=board, current_player=1, is_terminal=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
