{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1440ce-9dee-447c-93a5-65b8c7e889e3",
   "metadata": {},
   "source": [
    "# RGI scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d01a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generic, Literal, Sequence, Type, Any\n",
    "import dataclasses\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rgi.core.base import TGameState, TAction, TPlayerState\n",
    "from rgi.core.game_registry import GAME_REGISTRY\n",
    "from rgi.core.game_registry import PLAYER_REGISTRY\n",
    "\n",
    "from rgi.core import trajectory\n",
    "from rgi.core import game_runner\n",
    "from rgi.tests import test_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3bedd9",
   "metadata": {},
   "source": [
    "# Play game and record trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b363f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up game.\n",
    "from rgi.games.connect4 import connect4\n",
    "TGameState, TPlayerState, TAction = connect4.Connect4State, Literal[None], connect4.Action\n",
    "\n",
    "game = connect4.Connect4Game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2670bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoooooooooooooooooooooooooooooooo\n",
      "### rodo: magic: b'PK\\x03\\x04-\\x00'\n",
      "### rodo: magic is zip:\n",
      "### rodo: self._files: ['action_player_ids.npy', 'incremental_rewards.npy', 'final_reward.npy', 'num_players.npy', 'state_board.npy', 'state_current_player.npy', 'state_winner.npy', 'action_.npy']\n",
      "reloaded_trajectory_equal = True\n"
     ]
    }
   ],
   "source": [
    "# Run simple precomputed trajectory.\n",
    "importlib.reload(trajectory)\n",
    "importlib.reload(game_runner)\n",
    "\n",
    "players = [\n",
    "    test_utils.PresetPlayer[TGameState, TAction](actions=[2,2,2,2]),\n",
    "    test_utils.PresetPlayer[TGameState, TAction](actions=[1,3,4,5]),\n",
    "]\n",
    "\n",
    "runner = game_runner.GameRunner(game, players, verbose=False)\n",
    "original_trajectory = runner.run()\n",
    "\n",
    "# original_trajectory = trajectory.play_game_and_record_trajectory(game, players)\n",
    "original_trajectory.write('trajectory.npz', allow_pickle=False)\n",
    "reloaded_trajectory = trajectory.GameTrajectory.read('trajectory.npz', TGameState, TAction, allow_pickle=True)\n",
    "\n",
    "equality_checker = test_utils.EqualityChecker()\n",
    "print('reloaded_trajectory_equal =', (reloaded_trajectory_equal := equality_checker.check_equality(original_trajectory, reloaded_trajectory)))\n",
    "assert reloaded_trajectory_equal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b24f0",
   "metadata": {},
   "source": [
    "# Type Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d6fa48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [1, 2, 3]\n",
      "<class 'list'> [1, 2, 3]\n",
      "<class '__main__.SimpleData'> SimpleData(x=[1, 2, 3])\n",
      "<class 'list'> [1, 2, 3]\n",
      "<class '__main__.SimpleData'> SimpleData(x=[1, 2, 3])\n",
      "(Field(name='x',type=list[int],default=<dataclasses._MISSING_TYPE object at 0x7cead4db8830>,default_factory=<dataclasses._MISSING_TYPE object at 0x7cead4db8830>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=False,_field_type=_FIELD),)\n"
     ]
    }
   ],
   "source": [
    "xx = [1,2,3]\n",
    "print(type(xx), xx)\n",
    "\n",
    "xx: list[int] = [1,2,3]\n",
    "print(type(xx), xx)\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SimpleData:\n",
    "    x: list[int]\n",
    "\n",
    "sd = SimpleData(x=[1,2,3])\n",
    "print(type(sd), sd)\n",
    "print(type(sd.x), sd.x)\n",
    "\n",
    "sd.x = [1,2,3]\n",
    "print(type(sd), sd)\n",
    "\n",
    "print(dataclasses.fields(SimpleData))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09817c41",
   "metadata": {},
   "source": [
    "## Archive Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1c393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestItem(a=1, b='hello', f=1.0, t=(1, 'a'), x=array([1, 2, 3]), y=[1, 2, 3])\n",
      "TestItem(a=2, b='world', f=2.0, t=(2, 'b'), x=array([4, 5, 6]), y=[4, 5, 6])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from rgi.core import archive\n",
    "importlib.reload(archive)\n",
    "\n",
    "# mm = trajectory_archive.MemoryMappedArchive('test_archive', TGameState, TAction)\n",
    "#mm.add_trajectory(original_trajectory)\n",
    "#mm.save()\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TestItem:\n",
    "    a: int\n",
    "    b: str\n",
    "    f: float\n",
    "    t: tuple[int, str]\n",
    "    x: np.ndarray\n",
    "    y: list[int]\n",
    "\n",
    "list_based_archive = archive.ListBasedArchive(TestItem)\n",
    "list_based_archive.append(TestItem(a=1, b='hello', f=1.0, t=(1, 'a'), x=np.array([1, 2, 3]), y=[1, 2, 3]))\n",
    "list_based_archive.append(TestItem(a=2, b='world', f=2.0, t=(2, 'b'), x=np.array([4, 5, 6]), y=[4, 5, 6]))\n",
    "\n",
    "print(list_based_archive[0])\n",
    "print(list_based_archive[1])\n",
    "print(len(list_based_archive))\n",
    "\n",
    "# archive.MMappedArchive.save(list_based_archive, Path('test_archive.npz'))\n",
    "\n",
    "# mmapped_archive = archive.MMappedArchive(Path('test_archive.npz'), TestItem)\n",
    "# print(mmapped_archive[0])\n",
    "# print(mmapped_archive[1])\n",
    "# print(len(mmapped_archive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0bbd8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a <class 'int'>\n",
      "b <class 'str'>\n",
      "f <class 'float'>\n",
      "t tuple[int, str]\n",
      "x <class 'numpy.ndarray'>\n",
      "y list[int]\n",
      "{'a': array([1, 2]), 'b': array(['hello', 'world'], dtype='<U5'), 'f': array([1., 2.]), 't': array([['1', 'a'],\n",
      "       ['2', 'b']], dtype='<U21'), 'x': array([[1, 2, 3],\n",
      "       [4, 5, 6]]), 'y': array([[1, 2, 3],\n",
      "       [4, 5, 6]])}\n"
     ]
    }
   ],
   "source": [
    "T = TestItem\n",
    "\n",
    "from dataclasses import is_dataclass, fields\n",
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "\n",
    "def dataclass_to_npz_dict(obj: Any, prefix: str = \"\") -> Dict[str, np.ndarray]:\n",
    "    if not is_dataclass(obj):\n",
    "        raise TypeError(f\"Expected dataclass instance, got {type(obj)}\")\n",
    "        \n",
    "    result = {}\n",
    "    for field in fields(obj):\n",
    "        value = getattr(obj, field.name)\n",
    "        key = f\"{prefix}{field.name}\"\n",
    "        \n",
    "        # Convert value to numpy array if needed\n",
    "        if isinstance(value, np.ndarray):\n",
    "            result[key] = value\n",
    "        elif isinstance(value, (int, float)):\n",
    "            result[key] = np.array([value])\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            result[key] = np.array(value)\n",
    "        elif is_dataclass(value):\n",
    "            # Recursively handle nested dataclasses\n",
    "            nested_dict = dataclass_to_npz_dict(value, prefix=f\"{key}_\")\n",
    "            result.update(nested_dict)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type for field {field.name}: {type(value)}\")\n",
    "            \n",
    "    return result\n",
    "\n",
    "# Updated save method\n",
    "def save(item_type: type[T], archive: archive.Archive[T], filepath: Path) -> None:\n",
    "    \"\"\"Save archive to file\"\"\"\n",
    "    data_dict = {}\n",
    "    for i, item in enumerate(archive):\n",
    "        prefix = f\"item_{i}_\"\n",
    "        item_dict = dataclass_to_npz_dict(item, prefix=prefix)\n",
    "        data_dict.update(item_dict)\n",
    "\n",
    "    print(data_dict)\n",
    "    \n",
    "    np.savez_compressed(filepath, **data_dict)\n",
    "\n",
    "# save(list_based_archive, Path('test_archive.npz'))\n",
    "\n",
    "archive_dict = {}\n",
    "item_type = TestItem\n",
    "for field in dataclasses.fields(item_type):\n",
    "    print(field.name, field.type)\n",
    "    archive_dict[field.name] = np.array([getattr(item, field.name) for item in list_based_archive])\n",
    "\n",
    "print(archive_dict)\n",
    "\n",
    "# np.savez_compressed('test_archive.npz', **archive_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e034403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tt.a': {'tt.a': array([1, 2, 3, 4, 5])},\n",
       " 'tt.b': {'tt.b': array(['hello', 'world', 'foo', 'bar', 'baz'], dtype='<U5')},\n",
       " 'tt.f': {'tt.f': array([1., 2., 3., 4., 5.])},\n",
       " 'tt.t': {'tt.t.0': array([1, 2, 3, 4, 5]),\n",
       "  'tt.t.1': array(['a', 'b', 'c', 'd', 'e'], dtype='<U1')},\n",
       " 'tt.x': {'tt.x.*': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 77, 88, 99, 10, 11, 12, 13, 14,\n",
       "         15]),\n",
       "  'tt.x.#.*': array([3, 3, 2, 3, 3, 3]),\n",
       "  'tt.x.#.#': array([1, 1, 2, 1, 1])},\n",
       " 'tt.y': {'tt.y.*': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]),\n",
       "  'tt.y.#': array([3, 3, 3, 3, 3])}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# archive_dict = {}\n",
    "# item_type = TestItem\n",
    "# input_archive = list_based_archive\n",
    "\n",
    "import typing\n",
    "import types\n",
    "T = typing.TypeVar(\"T\")\n",
    "\n",
    "\n",
    "def serialize_to_dict(field_path: str, item_type: Type | types.GenericAlias, items: Sequence[T]) -> dict[str, Any]:\n",
    "    \n",
    "    if item_type in (int, float, str, bool):\n",
    "        return {field_path: np.array(items)}\n",
    "    \n",
    "    if is_dataclass(item_type):\n",
    "        d = {}\n",
    "        for field in dataclasses.fields(item_type):\n",
    "            # add type guard\n",
    "            field_type = field.type\n",
    "            if not isinstance(field_type, (Type, types.GenericAlias)):\n",
    "                raise ValueError(f\"Field {field.name} with field_type {field_type} is not a Type. Unable to serialize.\")\n",
    "\n",
    "            field_items = [getattr(item, field.name) for item in items]\n",
    "            field_key = f\"{field_path}.{field.name}\"\n",
    "            d[field_key] = serialize_to_dict(field_key, field_type, field_items)\n",
    "\n",
    "            # TODO: Handle indexes.\n",
    "            field_index = f\"#{field_path}.{field.name}\"\n",
    "        return d\n",
    "    \n",
    "    if isinstance(item_type, types.GenericAlias):\n",
    "        base_type = typing.get_origin(item_type)\n",
    "        base_type_args = typing.get_args(item_type)\n",
    "\n",
    "        # Handle variable length tuples of a single type (e.g. tuple[int, ...]) like they are a list.\n",
    "        # This is primiarily to handle np.array shapes.\n",
    "        if base_type is tuple and base_type_args[-1] is Ellipsis:\n",
    "            if len(base_type_args) != 2:\n",
    "                raise ValueError(f\"Tuple with ellipsis must have exactly 2 elements, got {len(base_type_args)} and type {base_type_args}\")\n",
    "            list_type = list[base_type_args[0]]\n",
    "            return serialize_to_dict(field_path, list_type, items)\n",
    "\n",
    "        if base_type is tuple:\n",
    "            if Ellipsis in base_type_args:\n",
    "                raise ValueError(f\"ellipsis only supported in tuples as a single last element, got type {item_type}\")\n",
    "            d = {}\n",
    "            for i, t in enumerate(base_type_args):\n",
    "                tuple_field_path = f\"{field_path}.{i}\"\n",
    "                tuple_field_items = [item[i] for item in items]  # type: ignore\n",
    "                tuple_serialized = serialize_to_dict(tuple_field_path, t, tuple_field_items)\n",
    "                d.update(tuple_serialized)\n",
    "            return d\n",
    "\n",
    "        if base_type is list:\n",
    "            unrolled_items = [item for item_list in items for item in item_list] # type: ignore\n",
    "            unrolled_lengths = [len(item_list) for item_list in items]  # type: ignore\n",
    "            values_dict = serialize_to_dict(f\"{field_path}.*\", base_type_args[0], unrolled_items)\n",
    "            length_dict = serialize_to_dict(f\"{field_path}.#\", int, unrolled_lengths)\n",
    "            return values_dict | length_dict\n",
    "\n",
    "    if item_type is np.ndarray:\n",
    "        flat_values = np.concatenate([arr.flatten() for arr in items]) # type: ignore\n",
    "        shapes = [arr.shape for arr in items] # type: ignore\n",
    "\n",
    "        values_dict = {f\"{field_path}.*\": flat_values}\n",
    "        shape_dict = serialize_to_dict(f\"{field_path}.#\", tuple[int, ...], shapes)\n",
    "        return values_dict | shape_dict\n",
    "        \n",
    "    raise NotImplementedError(f\"Cannot add fields for field `{field_path}` with non-dataclass type {item_type}\")\n",
    "\n",
    "\n",
    "assert np.array_equal(serialize_to_dict('a', int, range(10))['a'], np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n",
    "assert np.array_equal(serialize_to_dict('a', float, [0.1, 0.2, 0.3])['a'], np.array([0.1, 0.2, 0.3]))\n",
    "assert np.array_equal(serialize_to_dict('a', str, ['a', 'b', 'c'])['a'], np.array(['a', 'b', 'c']))\n",
    "assert np.array_equal(serialize_to_dict('a', bool, [True, False, True])['a'], np.array([True, False, True]))\n",
    "\n",
    "\n",
    "test_items = [\n",
    "    TestItem(a=1, b='hello', f=1.0, t=(1, 'a'), x=np.array([1, 2, 3]), y=[1, 2, 3]),\n",
    "    TestItem(a=2, b='world', f=2.0, t=(2, 'b'), x=np.array([4, 5, 6]), y=[4, 5, 6]),\n",
    "    TestItem(a=3, b='foo', f=3.0, t=(3, 'c'), x=np.array([[7, 8, 9], [77, 88, 99]]), y=[7, 8, 9]),\n",
    "    TestItem(a=4, b='bar', f=4.0, t=(4, 'd'), x=np.array([10, 11, 12]), y=[10, 11, 12]),\n",
    "    TestItem(a=5, b='baz', f=5.0, t=(5, 'e'), x=np.array([13, 14, 15]), y=[13, 14, 15]),\n",
    "]\n",
    "\n",
    "serialize_to_dict('tt', TestItem, test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bea560d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert isinstance(int, Type) and isinstance(float, Type) and isinstance(str, Type) and isinstance(bool, Type)\n",
    "dataclasses.is_dataclass(TestItem)\n",
    "# isinstance(tuple[int, str], Type)\n",
    "tuple[int, str].__class__\n",
    "list[int].__class__\n",
    "\n",
    "import types\n",
    "\n",
    "isinstance(tuple[int, str], types.GenericAlias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40f20262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListBasedArchive(item_type=<class '__main__.TestItem'>, len=0, items[:1]=[])\n",
      "ListBasedArchive(item_type=<class '__main__.TestItem'>, len=2, items[:1]=[TestItem(a=1, b='hello', f=1.0, t=(1, 'a'), x=array([1, 2, 3]), y=[1, 2, 3])])\n",
      "[TestItem(a=1, b='hello', f=1.0, t=(1, 'a'), x=array([1, 2, 3]), y=[1, 2, 3]), TestItem(a=2, b='world', f=2.0, t=(2, 'b'), x=array([4, 5, 6]), y=[4, 5, 6])]\n"
     ]
    }
   ],
   "source": [
    "import abc\n",
    "import typing\n",
    "\n",
    "class Archive(typing.Sequence[T], abc.ABC):\n",
    "    pass\n",
    "\n",
    "class AppendableArchive(Archive[T]):\n",
    "    @abc.abstractmethod\n",
    "    def append(self, item: T) -> None:\n",
    "        \"\"\"Add item to archive.\"\"\"\n",
    "\n",
    "# class ListBasedArchive(Archive[T]):\n",
    "class ListBasedArchive(AppendableArchive[T]):\n",
    "    def __init__(self, item_type: type[T]):\n",
    "        \"\"\"Initialize empty archive.\"\"\"\n",
    "        self._item_type = item_type\n",
    "        self._items: list[T] = []\n",
    "\n",
    "    @typing.override\n",
    "    def append(self, item: T) -> None:\n",
    "        \"\"\"Add item to archive.\"\"\"\n",
    "        self._items.append(item)\n",
    "\n",
    "    @typing.override\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._items)\n",
    "\n",
    "    @typing.override\n",
    "    def __getitem__(self, idx: int) -> T:\n",
    "        return self._items[idx]\n",
    "\n",
    "    @typing.override\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"ListBasedArchive(item_type={self._item_type}, len={len(self)}, items[:1]={self._items[:1]})\"\n",
    "    \n",
    "\n",
    "list_archive = ListBasedArchive(TestItem)\n",
    "\n",
    "assert isinstance(list_archive, Archive)\n",
    "assert isinstance(list_archive, Sequence)\n",
    "print(list_archive)\n",
    "list_archive.append(TestItem(a=1, b='hello', f=1.0, t=(1, 'a'), x=np.array([1, 2, 3]), y=[1, 2, 3]))\n",
    "list_archive.append(TestItem(a=2, b='world', f=2.0, t=(2, 'b'), x=np.array([4, 5, 6]), y=[4, 5, 6]))\n",
    "print(list_archive)\n",
    "print(list(list_archive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5fe9add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3]\n",
    "print(isinstance(x, list))\n",
    "print(isinstance(x, typing.Sequence))\n",
    "print(isinstance(x, typing.MutableSequence))\n",
    "print(isinstance(list_archive, typing.Sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7b4773c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unsupported type for field b: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data_dict)\n\u001b[1;32m     57\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez_compressed(filepath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_dict)\n\u001b[0;32m---> 59\u001b[0m \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_based_archive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_archive.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 52\u001b[0m, in \u001b[0;36msave\u001b[0;34m(archive, filepath)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(archive):\n\u001b[1;32m     51\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 52\u001b[0m     item_dict \u001b[38;5;241m=\u001b[39m \u001b[43mdataclass_to_npz_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     data_dict\u001b[38;5;241m.\u001b[39mupdate(item_dict)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_dict)\n",
      "Cell \u001b[0;32mIn[23], line 37\u001b[0m, in \u001b[0;36mdataclass_to_npz_dict\u001b[0;34m(obj, prefix)\u001b[0m\n\u001b[1;32m     35\u001b[0m         result\u001b[38;5;241m.\u001b[39mupdate(nested_dict)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported type for field \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: Unsupported type for field b: <class 'str'>"
     ]
    }
   ],
   "source": [
    "# Claude code\n",
    "T = TestItem\n",
    "\n",
    "from dataclasses import is_dataclass, fields\n",
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "\n",
    "def dataclass_to_npz_dict(obj: Any, prefix: str = \"\") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Convert a dataclass instance to a dictionary of numpy arrays.\n",
    "    \n",
    "    Args:\n",
    "        obj: Dataclass instance to convert\n",
    "        prefix: Prefix for dictionary keys\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping from field names to numpy arrays\n",
    "    \"\"\"\n",
    "    if not is_dataclass(obj):\n",
    "        raise TypeError(f\"Expected dataclass instance, got {type(obj)}\")\n",
    "        \n",
    "    result = {}\n",
    "    for field in fields(obj):\n",
    "        value = getattr(obj, field.name)\n",
    "        key = f\"{prefix}{field.name}\"\n",
    "        \n",
    "        # Convert value to numpy array if needed\n",
    "        if isinstance(value, np.ndarray):\n",
    "            result[key] = value\n",
    "        elif isinstance(value, (int, float)):\n",
    "            result[key] = np.array([value])\n",
    "        elif isinstance(value, (list, tuple)):\n",
    "            result[key] = np.array(value)\n",
    "        elif is_dataclass(value):\n",
    "            # Recursively handle nested dataclasses\n",
    "            nested_dict = dataclass_to_npz_dict(value, prefix=f\"{key}_\")\n",
    "            result.update(nested_dict)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type for field {field.name}: {type(value)}\")\n",
    "            \n",
    "    return result\n",
    "\n",
    "# Updated save method\n",
    "def save(archive: archive.Archive[T], filepath: Path) -> None:\n",
    "    \"\"\"Save archive to file.\n",
    "    \n",
    "    Args:\n",
    "        archive: Archive to save\n",
    "        filepath: Path to save to\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for i, item in enumerate(archive):\n",
    "        prefix = f\"item_{i}_\"\n",
    "        item_dict = dataclass_to_npz_dict(item, prefix=prefix)\n",
    "        data_dict.update(item_dict)\n",
    "\n",
    "    print(data_dict)\n",
    "    \n",
    "    np.savez_compressed(filepath, **data_dict)\n",
    "\n",
    "save(list_based_archive, Path('test_archive.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a219e",
   "metadata": {},
   "source": [
    "### Old Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Generic, TypeVar, Optional\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "TGameState = TypeVar(\"TGameState\")  # pylint: disable=invalid-name\n",
    "TAction = TypeVar(\"TAction\")  # pylint: disable=invalid-name\n",
    "TArchiveState = TypeVar(\"TArchiveState\")  # pylint: disable=invalid-name\n",
    "TArchiveAction = TypeVar(\"TArchiveAction\")  # pylint: disable=invalid-name\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Count21State:\n",
    "    score: int\n",
    "    current_player: int\n",
    "\n",
    "Count21Action = int\n",
    "\n",
    "@dataclass\n",
    "class Connect4State:\n",
    "    board: NDArray[np.int8]  # (height, width)\n",
    "    current_player: int\n",
    "    winner: Optional[int] = None  # The winner, if the game has ended\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Count21ArchiveState:\n",
    "    score: NDArray[np.int64]\n",
    "    current_player: NDArray[np.int8]\n",
    "\n",
    "Count21ArchiveAction = NDArray[np.int8]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Archive(Generic[TGameState, TAction, TArchiveState, TArchiveAction]):\n",
    "    pass\n",
    "\n",
    "print('done.')\n",
    "\n",
    "a = Archive[Count21State, Count21Action, Count21ArchiveState, Count21ArchiveAction]()\n",
    "\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Archive(Generic[TGameState, TArchiveState]):\n",
    "    def __init__(self):\n",
    "        # Get the actual types from the class's __orig_bases__ attribute\n",
    "        generic_base = self.__class__.__orig_bases__[0]\n",
    "        self.game_state_type = generic_base.__args__[0]\n",
    "        self.archive_state_type = generic_base.__args__[1]\n",
    "        \n",
    "        # Now we can inspect the fields\n",
    "        print(\"Game State fields:\", fields(self.game_state_type))\n",
    "        print(\"Archive State fields:\", fields(self.archive_state_type))\n",
    "        \n",
    "        # And get their type hints\n",
    "        print(\"Game State types:\", get_type_hints(self.game_state_type))\n",
    "        print(\"Archive State types:\", get_type_hints(self.archive_state_type))\n",
    "\n",
    "# Test it\n",
    "a = Archive[Count21State, Count21ArchiveState]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0703ba96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TArchiveState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mArchive\u001b[39;00m(Generic[TGameState, \u001b[43mTArchiveState\u001b[49m]):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;66;03m# Get the actual types from the class's __orig_bases__ attribute\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         generic_base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m__orig_bases__[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TArchiveState' is not defined"
     ]
    }
   ],
   "source": [
    "class Archive(Generic[TGameState, TArchiveState]):\n",
    "    def __init__(self):\n",
    "        # Get the actual types from the class's __orig_bases__ attribute\n",
    "        generic_base = self.__class__.__orig_bases__[0]\n",
    "        self.game_state_type = generic_base.__args__[0]  # This is the actual Count21State class\n",
    "        self.archive_state_type = generic_base.__args__[1]  # This is the actual Count21ArchiveState class\n",
    "        \n",
    "        # Initialize empty archive arrays based on the fields\n",
    "        self.archive = {}\n",
    "        game_state_fields = dataclasses.fields(self.game_state_type)\n",
    "        archive_state_fields = dataclasses.fields(self.archive_state_type)\n",
    "        \n",
    "        # Map field names to their numpy types\n",
    "        for game_field, archive_field in zip(game_state_fields, archive_state_fields):\n",
    "            print(f\"Field {game_field.name}: {game_field.type} -> {archive_field.type}\")\n",
    "            # Initialize empty array for this field\n",
    "            # We'll need to determine the numpy dtype based on the archive field type\n",
    "\n",
    "    def add(self, state: TGameState) -> None:\n",
    "        # Convert each field to the appropriate numpy array\n",
    "        for field in dataclasses.fields(state):\n",
    "            value = getattr(state, field.name)\n",
    "            print(f\"Adding {field.name}: {value}\")\n",
    "\n",
    "# Test it\n",
    "a = Archive[Count21State, Count21ArchiveState]()\n",
    "a.add(Count21State(score=1, current_player=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dataclasses\n",
    "class Archive(Generic[TGameState, TArchiveState]):\n",
    "    def __init__(self):\n",
    "        # Get the actual types from the class's __orig_bases__ attribute\n",
    "        generic_base = self.__class__.__orig_bases__[0]\n",
    "        self.game_state_type = generic_base.__args__[0]\n",
    "        self.archive_state_type = generic_base.__args__[1]\n",
    "\n",
    "        self.archive = TArchiveState()\n",
    "\n",
    "    def add(self, state: TGameState) -> None:\n",
    "        print(dataclasses.fields(state))\n",
    "        print(dataclasses.fields(self.archive))\n",
    "\n",
    "\n",
    "a = Archive[Count21State, Count21ArchiveState]()\n",
    "a.add(Count21State(score=1, current_player=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "class Batch(Generic[T]):\n",
    "    \"\"\"Convenience class to convert a sequence of states & actions into a batch.\n",
    "\n",
    "    >>> from dataclasses import dataclass\n",
    "    >>> import torch\n",
    "    >>> @dataclass\n",
    "    ... class GameState:\n",
    "    ...     score: int\n",
    "    ...     current_player: int\n",
    "    >>> @dataclass\n",
    "    ... class BatchGameState(Batch[GameState]):\n",
    "    ...     score: torch.Tensor\n",
    "    ...     current_player: torch.Tensor\n",
    "    >>> states = [GameState(5, 1), GameState(7, 2)]\n",
    "    >>> batch = BatchGameState.from_sequence(states)\n",
    "    >>> len(batch)\n",
    "    2\n",
    "    >>> batch\n",
    "    BatchGameState(score=tensor([5, 7]), current_player=tensor([1, 2]))\n",
    "    >>> batch[0]\n",
    "    GameState(score=5, current_player=1)\n",
    "    \"\"\"\n",
    "\n",
    "    _unbatch_class: Type[T]\n",
    "\n",
    "    @classmethod\n",
    "    def from_sequence(cls: Type[TBatch], items: Sequence[T]) -> TBatch:\n",
    "        if not items:\n",
    "            raise ValueError(\"Cannot create a batch from an empty sequence\")\n",
    "\n",
    "        cls_fields = set(f.name for f in fields(cls))  # type: ignore\n",
    "        batch_dict = {}\n",
    "        for field in fields(items[0]):  # type: ignore\n",
    "            if field.name not in cls_fields:\n",
    "                continue\n",
    "            values = [getattr(item, field.name) for item in items]\n",
    "            # We need to handle both primitive values and torch.Tensors here.\n",
    "            # torch.tensor(primitive_list) is probably more efficient, but doesn't work for tensors.\n",
    "            batch_dict[field.name] = torch.stack([torch.tensor(value) for value in values])\n",
    "\n",
    "        batch = cls(**batch_dict)\n",
    "        batch._unbatch_class = type(items[0])\n",
    "        return batch\n",
    "\n",
    "    def __getitem__(self, index: int) -> T:\n",
    "        item_dict = {field.name: field.type(getattr(self, field.name)[index]) for field in fields(self)}  # type: ignore\n",
    "        return self._unbatch_class(**item_dict)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(getattr(self, fields(self)[0].name))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batchable(Protocol[T]):\n",
    "    \"\"\"Protocol to convert single states & actions into torch.Tensor for batching.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def from_sequence(items: Sequence[T]) -> \"Batchable[T]\": ...\n",
    "\n",
    "    def __getitem__(self, index: int) -> T: ...\n",
    "\n",
    "    def __len__(self) -> int: ...\n",
    "\n",
    "\n",
    "class Batch(Generic[T]):\n",
    "    \"\"\"Convenience class to convert a sequence of states & actions into a batch.\n",
    "\n",
    "    >>> from dataclasses import dataclass\n",
    "    >>> import torch\n",
    "    >>> @dataclass\n",
    "    ... class GameState:\n",
    "    ...     score: int\n",
    "    ...     current_player: int\n",
    "    >>> @dataclass\n",
    "    ... class BatchGameState(Batch[GameState]):\n",
    "    ...     score: torch.Tensor\n",
    "    ...     current_player: torch.Tensor\n",
    "    >>> states = [GameState(5, 1), GameState(7, 2)]\n",
    "    >>> batch = BatchGameState.from_sequence(states)\n",
    "    >>> len(batch)\n",
    "    2\n",
    "    >>> batch\n",
    "    BatchGameState(score=tensor([5, 7]), current_player=tensor([1, 2]))\n",
    "    >>> batch[0]\n",
    "    GameState(score=5, current_player=1)\n",
    "    \"\"\"\n",
    "\n",
    "    _unbatch_class: Type[T]\n",
    "\n",
    "    @classmethod\n",
    "    def from_sequence(cls: Type[TBatch], items: Sequence[T]) -> TBatch:\n",
    "        if not items:\n",
    "            raise ValueError(\"Cannot create a batch from an empty sequence\")\n",
    "\n",
    "        cls_fields = set(f.name for f in fields(cls))  # type: ignore\n",
    "        batch_dict = {}\n",
    "        for field in fields(items[0]):  # type: ignore\n",
    "            if field.name not in cls_fields:\n",
    "                continue\n",
    "            values = [getattr(item, field.name) for item in items]\n",
    "            # We need to handle both primitive values and torch.Tensors here.\n",
    "            # torch.tensor(primitive_list) is probably more efficient, but doesn't work for tensors.\n",
    "            batch_dict[field.name] = torch.stack([torch.tensor(value) for value in values])\n",
    "\n",
    "        batch = cls(**batch_dict)\n",
    "        batch._unbatch_class = type(items[0])\n",
    "        return batch\n",
    "\n",
    "    def __getitem__(self, index: int) -> T:\n",
    "        item_dict = {field.name: field.type(getattr(self, field.name)[index]) for field in fields(self)}  # type: ignore\n",
    "        return self._unbatch_class(**item_dict)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(getattr(self, fields(self)[0].name))  # type: ignore\n",
    "\n",
    "@dataclass\n",
    "class PrimitiveBatch(Generic[T]):\n",
    "    \"\"\"A batch class for primitive types like int, float, etc.\n",
    "\n",
    "    >>> batch = PrimitiveBatch.from_sequence([2,4,6,8])\n",
    "    >>> len(batch)\n",
    "    4\n",
    "    >>> batch\n",
    "    PrimitiveBatch(values=tensor([2, 4, 6, 8]))\n",
    "    >>> batch[0]\n",
    "    2\n",
    "    \"\"\"\n",
    "\n",
    "    values: torch.Tensor\n",
    "\n",
    "    @classmethod\n",
    "    def from_sequence(cls: Type[\"PrimitiveBatch[T]\"], items: Sequence[T]) -> \"PrimitiveBatch[T]\":\n",
    "        if not items:\n",
    "            raise ValueError(\"Cannot create a batch from an empty sequence\")\n",
    "\n",
    "        return cls(values=torch.tensor(items))\n",
    "\n",
    "    def __getitem__(self, index: int) -> T:\n",
    "        return self.values[index].item()  # type: ignore\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.values.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Generic\n",
    "\n",
    "TGameState = TypeVar('TGameState')\n",
    "TArchiveState = TypeVar('TArchiveState')\n",
    "\n",
    "class Archive(Generic[TGameState, TArchiveState]):\n",
    "    def __init__(self):\n",
    "        # Access the original class with type parameters\n",
    "        orig_class = self.__orig_class__\n",
    "        # Extract the type arguments\n",
    "        t_game_state, t_archive_state = orig_class.__args__\n",
    "        print(f\"TGameState type: {t_game_state}\")\n",
    "        print(f\"TArchiveState type: {t_archive_state}\")\n",
    "\n",
    "# Example classes\n",
    "class Foo:\n",
    "    pass\n",
    "\n",
    "class Bar:\n",
    "    pass\n",
    "\n",
    "# Create an instance with specific types\n",
    "a = Archive[Foo, Bar]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Type, TypeVar, Generic\n",
    "\n",
    "TGameState = TypeVar('TGameState')\n",
    "TArchiveState = TypeVar('TArchiveState')\n",
    "\n",
    "@dataclass\n",
    "class Archive(Generic[TGameState, TArchiveState]):\n",
    "    _game_state_type: Type[TGameState] = field(init=False, repr=False)\n",
    "    _archive_state_type: Type[TArchiveState] = field(init=False, repr=False)\n",
    "\n",
    "    def __init__(self, game_state_type: Type[TGameState], archive_state_type: Type[TArchiveState]):\n",
    "        self._game_state_type = game_state_type\n",
    "        self._archive_state_type = archive_state_type\n",
    "        print(f\"TGameState type: {self._game_state_type}\")\n",
    "        print(f\"TArchiveState type: {self._archive_state_type}\")\n",
    "\n",
    "# Define Foo and Bar as example dataclasses\n",
    "@dataclass\n",
    "class Foo:\n",
    "    name: str = \"Foo example\"\n",
    "\n",
    "@dataclass\n",
    "class Bar:\n",
    "    value: int = 42\n",
    "\n",
    "# Instantiate Archive by passing the types\n",
    "a = Archive(Foo, Bar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Type, TypeVar, Generic\n",
    "\n",
    "TGameState = TypeVar('TGameState')\n",
    "TArchiveState = TypeVar('TArchiveState')\n",
    "\n",
    "class Archive(Generic[TGameState, TArchiveState]):\n",
    "\n",
    "    def __init__(self, game_state_type: Type[TGameState], archive_state_type: Type[TArchiveState]):\n",
    "        self._game_state_type = game_state_type\n",
    "        self._archive_state_type = archive_state_type\n",
    "        print(f\"TGameState type: {self._game_state_type}\")\n",
    "        print(f\"TArchiveState type: {self._archive_state_type}\")\n",
    "\n",
    "# Define Foo and Bar as example dataclasses\n",
    "@dataclass\n",
    "class Foo:\n",
    "    name: str = \"Foo example\"\n",
    "\n",
    "@dataclass\n",
    "class Bar:\n",
    "    value: int = 42\n",
    "\n",
    "# Instantiate Archive by passing the types\n",
    "a = Archive(Foo, Bar)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
